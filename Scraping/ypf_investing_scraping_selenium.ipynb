{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26/04/2023\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El objetivo de este trabajo es obtener datos de un activo financiero utilizando técnicas de web scraping y almacenarlos en una base de datos SQL. Estas tareas se realizarán de forma frecuente cada minuto hasta que se decida interrumpir el proceso. Además, se realizará un análisis de los datos obtenidos.\n",
    "\n",
    "En este caso, se ha seleccionado el activo financiero YPF S.A de Buenos Aires, con el símbolo YPFD en investing.com.\n",
    "\n",
    "Las librerías que se utilizarán en este proyecto son las siguientes:\n",
    "\n",
    "* Selenium, para realizar el web scraping.\n",
    "* sqlite3, para establecer la conexión con la base de datos SQL.\n",
    "* datetime y schedule, para programar la ejecución repetitiva de la tarea cada 1 minuto.\n",
    "* csv, para guardar los datos en un archivo CSV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import schedule\n",
    "import time\n",
    "import csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping con Selenium\n",
    "### Conexión con el driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opciones de navegacion\n",
    "\n",
    "options =  webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('--disable-extensions')\n",
    "\n",
    "driver_path = Service(\"C:\\\\Users\\\\Tatu\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "driver = webdriver.Chrome(service = driver_path, options = options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acciones YPF | Cotización BA:YPFD hoy - Investing.com\n"
     ]
    }
   ],
   "source": [
    "# Conexion con la pagina\n",
    "driver.get('https://es.investing.com/equities/ypf-sociedad')\n",
    "\n",
    "tit=driver.title\n",
    "print(tit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:36:25.905009\n"
     ]
    }
   ],
   "source": [
    "# Insertar fecha y hora actual\n",
    "now = datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los datos\n",
    "Se debe actualizar el fullXPath, no se mantiene siempre igual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtencion de los datos con el fullXPath\n",
    "\n",
    "ultimo_cierre = driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[1]/dd/span/span[1]')\n",
    "ultimo_cierre = ultimo_cierre.text\n",
    "print(\"Último cierre \" + ultimo_cierre)\n",
    "\n",
    "rango_min = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[3]/dd/span[1]/span[1]')\n",
    "rango_min = rango_min.text\n",
    "print(\"Mínimo \" + rango_min)\n",
    "\n",
    "rango_max = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[3]/dd/span[3]/span[1]')\n",
    "rango_max = rango_max.text\n",
    "print(\"Máximo \" + rango_max)\n",
    "\n",
    "ingresos_T = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[2]/div[2]/dd/span/span[1]')\n",
    "ingresos_T = ingresos_T.text\n",
    "print(\"Ingresos \" + ingresos_T + \"T\")\n",
    "\n",
    "apertura = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[2]/dd/span/span[1]')\n",
    "apertura = apertura.text\n",
    "print(\"Apertura \" + apertura)\n",
    "\n",
    "\n",
    "volumen = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[5]/dd/span/span[1]')\n",
    "volumen = volumen.text\n",
    "print(\"Volumen \" + volumen)\n",
    "\n",
    "volumen_promedio = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[5]/div[1]/dl[1]/div[6]/dd/span/span[1]')\n",
    "volumen_promedio = volumen_promedio.text\n",
    "print(\"Volumen promedio \" + volumen_promedio)\n",
    "\n",
    "ultimo_precio = driver.find_element(By.XPATH, '/html/body/div/div[2]/div[2]/div/div[1]/div/div[1]/div[3]/div/div[1]/div[1]')\n",
    "ultimo_precio = ultimo_precio.text\n",
    "print(\"Último precio \" + ultimo_precio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar el driver\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar los datos obtenidos en una base de datos SQL\n",
    "### Conexión con sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conexión con la base de datos\n",
    "conn = sqlite3.connect('acciones_YPFD.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de la tabla \"resumen\"\n",
    "#c.execute('''CREATE TABLE resumen\n",
    "#             (date_time DATETIME, ultimo_precio REAL, minimo REAL, maximo REAL, ingresos REAL, apertura REAL, volumen REAL, volumen_promedio REAL)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar datos en la tabla\n",
    "c.execute(\"INSERT INTO resumen (date_time, ultimo_cierre, minimo, maximo, ingresos, apertura, volumen, volumen_promedio, ultimo_precio) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\", \n",
    "          (now, ultimo_cierre, rango_min, rango_max, ingresos_T, apertura, volumen, volumen_promedio, ultimo_precio))\n",
    "\n",
    "# Guardar los cambios en la base de datos y cerrar la conexión\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2023-05-05 23:11:14.474165', '4.768,75', 4.841, '5.229,9', '2,53', 4.841, 322.677, 304.817)\n"
     ]
    }
   ],
   "source": [
    "# Ver los datos guardados\n",
    "# Seleccionar los datos de la tabla\n",
    "c.execute(\"SELECT * FROM resumen\")\n",
    "\n",
    "# Obtener los resultados de la consulta\n",
    "resultados = c.fetchall()\n",
    "\n",
    "# Imprimir los resultados en la consola\n",
    "for fila in resultados:\n",
    "    print(fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de los datos cada minuto\n",
    "Utilizamos la librería shedule para que el script se corra cada un minuto e ir obteniendo los valores actualizados. \n",
    "\n",
    "Primero creamos la función web_scraping() y copiamos el script utilizado. Esto nos servirá para posteriormente ejecutarlo cada un minuto con schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear la función para utilizar en schedule\n",
    "def web_scraping():\n",
    "\n",
    "    #Opciones de navegacion\n",
    "    options =  webdriver.ChromeOptions()\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-extensions')\n",
    "\n",
    "    driver_path = Service(\"C:\\\\Users\\\\Tatu\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "    driver = webdriver.Chrome(service = driver_path, options = options)\n",
    "\n",
    "    # Conexion con la pagina\n",
    "    driver.get('https://es.investing.com/equities/ypf-sociedad')\n",
    "\n",
    "    # Dejar que cargue la página\n",
    "    time.sleep(5)\n",
    "\n",
    "    tit=driver.title\n",
    "    print(tit)\n",
    "\n",
    "    # Insertar fecha y hora actual\n",
    "    now = datetime.now()\n",
    "    print(now)\n",
    "\n",
    "    # Obtener los datos con el fullXPath\n",
    "\n",
    "    ultimo_cierre = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[1]/dd/span/span[1]')\n",
    "    ultimo_cierre = ultimo_cierre.text\n",
    "    print(\"Último cierre \" + ultimo_cierre)\n",
    "\n",
    "    rango_min = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[2]/dd/span[1]/span[1]')\n",
    "    rango_min = rango_min.text\n",
    "    print(\"Mínimo \" + rango_min)\n",
    "\n",
    "    rango_max = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[2]/dd/span[3]/span[1]')\n",
    "    rango_max = rango_max.text\n",
    "    print(\"Máximo \" + rango_max)\n",
    "\n",
    "    ingresos_T = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[3]/dd/span/span[1]')\n",
    "    ingresos_T = ingresos_T.text\n",
    "    print(\"Ingresos \" + ingresos_T + \"T\")\n",
    "\n",
    "    apertura = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[4]/dd/span/span[1]')\n",
    "    apertura = apertura.text\n",
    "    print(\"Apertura \" + apertura)\n",
    "\n",
    "\n",
    "    volumen = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[7]/dd/span/span[1]')\n",
    "    volumen = volumen.text\n",
    "    print(\"Volumen \" + volumen)\n",
    "\n",
    "    volumen_promedio = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div/div[2]/main/div/div[8]/div/div[2]/dl/div[10]/dd/span/span[1]')\n",
    "    volumen_promedio = volumen_promedio.text\n",
    "    print(\"Volumen promedio \" + volumen_promedio)   \n",
    "\n",
    "    # Cerrar el driver\n",
    "    driver.close()\n",
    "\n",
    "    # Conexion con la base de datos\n",
    "    conn = sqlite3.connect('acciones_YPFD.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insertar datos en la tabla\n",
    "    cursor.execute(\"INSERT INTO resumen (date_time, ultimo_cierre, minimo, maximo, ingresos, apertura, volumen, volumen_promedio, ultimo_precio) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\", \n",
    "               (now, ultimo_cierre, rango_min, rango_max, ingresos_T, apertura, volumen, volumen_promedio, ultimo_precio))\n",
    "\n",
    "    # Guardar los cambios en la base de datos y cerrar la conexión\n",
    "    conn.commit()\n",
    "\n",
    "    # Ver los datos guardados\n",
    "    # Seleccionar los datos de la tabla\n",
    "    cursor.execute(\"SELECT * FROM resumen\")\n",
    "\n",
    "    # Obtener los resultados de la consulta\n",
    "    resultados = cursor.fetchall()\n",
    "\n",
    "    # Imprimir los resultados en la consola\n",
    "    for fila in resultados:\n",
    "        print(fila)\n",
    "\n",
    "    # Cerrar la conexión a la base de datos\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2023-05-05 23:11:14.474165', '4.768,75', 4.841, '5.229,9', '2,53', 4.841, 322.677, 304.817)\n",
      "('2023-05-08 15:10:10.264048', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 158.556, 304.817)\n",
      "('2023-05-08 15:10:27.563116', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 158.626, 304.817)\n",
      "('2023-05-08 16:26:44.078323', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 200.111, 304.817)\n",
      "('2023-05-08 16:27:57.916936', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 202.436, 304.817)\n",
      "('2023-05-08 16:32:20.396239', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 203.411, 304.817)\n",
      "('2023-05-08 16:49:32.928998', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 211.215, 304.817)\n",
      "('2023-05-08 19:31:30.464894', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:32:30.624894', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:32:54.260681', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:33:47.194170', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:34:13.078297', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:35:29.640297', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:35:46.814943', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:45:41.764638', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:50:32.305150', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:50:48.720648', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:52:04.958080', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 19:52:25.745308', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-08 21:53:14.340922', '5.202,55', 5.217, '5.376,1', '2,53', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 00:57:45.392207', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 00:59:09.451962', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:18:06.696088', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:21:16.341476', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:23:01.595538', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:35:18.270958', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:48:02.847387', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:52:37.952450', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:55:00.822994', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 01:58:11.492815', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 02:04:49.499466', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 02:05:52.275342', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 02:06:11.262482', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 02:06:44.417615', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n",
      "('2023-05-09 02:08:38.131385', '5.202,55', 5.217, '5.376,1', '2,09', 5.217, 229.0, 310.936)\n"
     ]
    }
   ],
   "source": [
    "# Ver los datos guardados\n",
    "# Conexion con la base de datos\n",
    "conn = sqlite3.connect('acciones_YPFD.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Seleccionar los datos de la tabla\n",
    "cursor.execute(\"SELECT * FROM resumen\")\n",
    "\n",
    "# Obtener los resultados de la consulta\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "# Imprimir los resultados en la consola\n",
    "for fila in resultados:\n",
    "    print(fila)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programar la ejecución cada minuto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programar la ejecución del scraping cada minuto\n",
    "schedule.every().minute.do(web_scraping)\n",
    "\n",
    "# Ejecutar el programa continuamente\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar datos en archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir conexión a la base de datos sqlite\n",
    "conn = sqlite3.connect('acciones_YPFD.db')\n",
    "\n",
    "# Seleccionar los datos\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM resumen\")\n",
    "\n",
    "# Crear archivo CSV y escribir datos\n",
    "with open('resumen_YPF.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    # Escribir encabezados de columnas\n",
    "    csvwriter.writerow([i[0] for i in cursor.description])  \n",
    "    csvwriter.writerows(cursor)\n",
    "\n",
    "# Cerrar conexión a la base de datos\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Se pudieron obtener los datos utilizando el xpath, ya que tanto el nombre como la clase de las variables eran identicos en la mayoría de los casos. Sin embargo, al volver a acceder a la página, el xpath cambió con frecuencia, lo que requirió actualizar constantemente el código. Esto impidió ejecutar la función programada cada minuto como se había planificado utilizando la función de schedule.\n",
    "\n",
    "Después de ejecutar el script varias veces, enfrentando errores debido a los cambios en el xpath, se lograron obtener 35 valores, como se muestra en la tabla resultante.\n",
    "\n",
    "Debido a la ineficacia del script para obtener datos de manera frecuente y confiable, se ha decidido continuar el análisis del activo financiero utilizando datos obtenidos a través de una API. Esto permite obtener una mayor cantidad de datos en menos tiempo.\n",
    "\n",
    "Es importante destacar que una técnica alternativa para realizar web scraping en nuestra URL es el scraping visual. En este enfoque, se realizarían capturas de pantalla de la página web y se utilizaría procesamiento de imágenes para identificar los elementos deseados. Sin embargo, por el momento se descarta esta técnica debido a su mayor complejidad y requerimiento de más tiempo y recursos\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
